{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb791f77",
   "metadata": {},
   "source": [
    "### LSTM Model\n",
    "长短期记忆网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2682d285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in d:\\anaconda\\envs\\python3.9\\lib\\site-packages (3.6.0)\n",
      "Requirement already satisfied: filelock in d:\\anaconda\\envs\\python3.9\\lib\\site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\anaconda\\envs\\python3.9\\lib\\site-packages (from datasets) (1.23.5)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in d:\\anaconda\\envs\\python3.9\\lib\\site-packages (from datasets) (18.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in d:\\anaconda\\envs\\python3.9\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in d:\\anaconda\\envs\\python3.9\\lib\\site-packages (from datasets) (2.0.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in d:\\anaconda\\envs\\python3.9\\lib\\site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in d:\\anaconda\\envs\\python3.9\\lib\\site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in d:\\anaconda\\envs\\python3.9\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in d:\\anaconda\\envs\\python3.9\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in d:\\anaconda\\envs\\python3.9\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2024.2.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in d:\\anaconda\\envs\\python3.9\\lib\\site-packages (from datasets) (0.32.4)\n",
      "Requirement already satisfied: packaging in d:\\anaconda\\envs\\python3.9\\lib\\site-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\anaconda\\envs\\python3.9\\lib\\site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in d:\\anaconda\\envs\\python3.9\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.9)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\anaconda\\envs\\python3.9\\lib\\site-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anaconda\\envs\\python3.9\\lib\\site-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda\\envs\\python3.9\\lib\\site-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\anaconda\\envs\\python3.9\\lib\\site-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\envs\\python3.9\\lib\\site-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
      "Requirement already satisfied: colorama in d:\\anaconda\\envs\\python3.9\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\anaconda\\envs\\python3.9\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\anaconda\\envs\\python3.9\\lib\\site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in d:\\anaconda\\envs\\python3.9\\lib\\site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in d:\\anaconda\\envs\\python3.9\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in d:\\anaconda\\envs\\python3.9\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in d:\\anaconda\\envs\\python3.9\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\anaconda\\envs\\python3.9\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\anaconda\\envs\\python3.9\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\anaconda\\envs\\python3.9\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in d:\\anaconda\\envs\\python3.9\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in d:\\anaconda\\envs\\python3.9\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\n",
      "Requirement already satisfied: six>=1.5 in d:\\anaconda\\envs\\python3.9\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87e9a69c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1f25353ae90>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from datasets import load_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "torch.manual_seed(12046)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3db4d659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义超参\n",
    "learning_rate = 1e-3\n",
    "eval_iters = 10\n",
    "batch_size=1000\n",
    "seq_len=64\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e4caa5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_datasets = load_dataset('code_search_net', 'python')\n",
    "datasets = raw_datasets['train'].filter(lambda x: 'apache/spark' in x['repository_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "458bc089",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharTokenizer:\n",
    "    def __init__(self, data, end_ind=0):\n",
    "        # data : list[str]\n",
    "        chars = sorted(list(set(\"\".join(data))))\n",
    "        self.char2ind = {char: i + 1 for i, char in enumerate(chars)}\n",
    "        # self.char2ind[\"<|b|>\"] = begin_ind\n",
    "        self.char2ind[\"<|e|>\"] = end_ind\n",
    "        self.ind2char = {i: char for char, i in self.char2ind.items()}\n",
    "        # self.begin_ind = begin_ind\n",
    "        self.end_ind = end_ind\n",
    "\n",
    "    def encode(self, text):\n",
    "        # text : str\n",
    "        return [self.char2ind[i] for i in text]\n",
    "\n",
    "    def decode(self, inds):\n",
    "        # inds : list[int] or int\n",
    "        if isinstance(inds, int):\n",
    "            inds = [inds]\n",
    "        return [self.ind2char[i] for i in inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f1f45c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = CharTokenizer(datasets[\"whole_func_string\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad75bfe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def generate(model, context, tokenizer, max_tokens=300):\n",
    "    # context: (1, T)\n",
    "    out = context.tolist()[0]  # (T, )\n",
    "    model.eval()\n",
    "    for _ in range(max_tokens):\n",
    "        logits = model(context)  # (1, T, 98)\n",
    "        probs = F.softmax(logits[:, -1, :], dim=-1)  # (1, T, 98) -> (1, 98)\n",
    "        next_token = torch.multinomial(probs, 1)  # (1, 1)\n",
    "        out.append(next_token.item())\n",
    "        context = torch.concat([context, next_token], dim=-1)  # (1, T + 1)\n",
    "        if out[-1] == tokenizer.end_ind:\n",
    "            break\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6515e855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 准备数据\n",
    "def process(data, tokenizer, seq_len=seq_len):\n",
    "    text = data[\"whole_func_string\"]\n",
    "    inputs, labels = [], []\n",
    "    for t in text:\n",
    "        # t: str\n",
    "        enc = tokenizer.encode(t)\n",
    "        enc += [tokenizer.end_ind]\n",
    "        for i in range(len(enc) - seq_len):\n",
    "            inputs.append(enc[i : i + seq_len])\n",
    "            labels.append(enc[i + 1 : i + seq_len + 1])\n",
    "    return {\"inputs\": inputs, \"labels\": labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2aa6dc7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([605913, 64]),\n",
       " torch.Size([605913, 64]),\n",
       " torch.Size([62633, 64]),\n",
       " torch.Size([62633, 64]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将数据分为训练集和测试集\n",
    "tokenized = datasets.train_test_split(test_size=0.1, seed=1024, shuffle=True)\n",
    "\n",
    "f = lambda x: process(x, tokenizer)\n",
    "tokenized = tokenized.map(f, batched=True, remove_columns=datasets.column_names)\n",
    "tokenized.set_format(type='torch', device=device)\n",
    "\n",
    "tokenized['train']['inputs'].shape, tokenized['train']['labels'].shape, tokenized['test']['inputs'].shape, tokenized['test']['labels'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42059e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(tokenized['train'], batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(tokenized['test'], batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f4043bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = F.cross_entropy\n",
    "\n",
    "# 计算损失\n",
    "def estimate_loss(model):\n",
    "    model.eval()\n",
    "    re = {}\n",
    "    with torch.no_grad():\n",
    "        re['train'] = _loss(model, train_loader)\n",
    "        re['test'] = _loss(model, test_loader)\n",
    "    model.train()\n",
    "    return re\n",
    "\n",
    "@torch.no_grad()\n",
    "def _loss(model, dataloader):\n",
    "    total_loss = []\n",
    "    data_iter = iter(dataloader)\n",
    "    for k in range(eval_iters): # 手动控制批次数量\n",
    "        data = next(data_iter, None)\n",
    "        if data is None:\n",
    "            data_iter = iter(dataloader)\n",
    "            data = next(data_iter, None)\n",
    "        inputs, labels = data['inputs'], data['labels']\n",
    "        logits = model(inputs)                               # (B, T, vs)\n",
    "        loss = criterion(logits.transpose(-2, -1), labels)\n",
    "        total_loss.append(loss.item())\n",
    "    return torch.tensor(total_loss).mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f65e746b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, epochs=10):\n",
    "    lossi = []\n",
    "    for epoch in range(epochs):\n",
    "        for i, data in enumerate(train_loader):\n",
    "            inputs, labels = data['inputs'], data['labels']  # (B, T)\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(inputs)\n",
    "            loss = F.cross_entropy(logits.transpose(-2, -1), labels)  # (B, T, vs) -> (B, vs, T)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            lossi.append(loss.item())\n",
    "        stats = estimate_loss(model)\n",
    "        train_loss = f\"{stats['train']:.4f}\"\n",
    "        test_loss = f\"{stats['test']:.4f}\"\n",
    "        print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {train_loss} | Test Loss: {test_loss}\")\n",
    "    return lossi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff77a1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMCell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        combined_size = input_size + hidden_size\n",
    "        self.forget_gate = nn.Linear(combined_size, hidden_size)\n",
    "        self.in_gate = nn.Linear(combined_size, hidden_size)\n",
    "        self.new_cell_state = nn.Linear(combined_size, hidden_size)\n",
    "        self.out_gate = nn.Linear(combined_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, state=None):\n",
    "        # input: (B, I)\n",
    "        # state: ((B, H), (B, H))\n",
    "        B = input.shape[0]\n",
    "        if state is None:\n",
    "            state = self.init_state(B, input.device)\n",
    "        hs, cs = state\n",
    "        combined = torch.concat((input, hs), dim=-1) # (B, I + H)\n",
    "        # 更新细胞状态\n",
    "        forgetgate = F.sigmoid(self.forget_gate(combined))\n",
    "        ingate = F.sigmoid(self.in_gate(combined))\n",
    "        ncs = F.tanh(self.new_cell_state(combined))\n",
    "        cs = (cs * forgetgate) + (ncs * ingate)\n",
    "        # 更新隐藏状态\n",
    "        outgate = F.sigmoid(self.out_gate(combined))\n",
    "        hs = F.tanh(cs) * outgate\n",
    "\n",
    "        return hs, cs\n",
    "    \n",
    "    def init_state(self, B, device):\n",
    "        hs = torch.zeros((B, self.hidden_size), device=device)\n",
    "        cs = torch.zeros((B, self.hidden_size), device=device)\n",
    "        return hs, cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34ff6bef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 4]), torch.Size([5, 4]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_cell = LSTMCell(3, 4)\n",
    "x = torch.randn(5, 3)\n",
    "a, b = l_cell(x)\n",
    "a.shape, b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ae21833",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.cell = LSTMCell(input_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, state=None):\n",
    "        # input: (B, T, C)\n",
    "        # state: ((B, H), (B, H))\n",
    "        # output: (B, T, H)\n",
    "        B, T, C = input.shape\n",
    "        re = [] # 输出列表\n",
    "        for i in range(T):\n",
    "            state = self.cell(input[:, i, :], state)\n",
    "            re.append(state[0]) # T 个 (B, H) 把 hidden 取出来\n",
    "        return torch.stack(re, dim=1) # (B, T, H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "932898d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(True), (5, 17, 1, 7, 15))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_lstm():\n",
    "    '''\n",
    "    测试LSTM实现的准确性\n",
    "    '''\n",
    "    # 随机生成模型结构\n",
    "    B, T, input_size, hidden_size, num_layers = torch.randint(1, 20, (5,)).tolist()\n",
    "    ref_model = nn.LSTM(input_size, hidden_size, num_layers=num_layers, batch_first=True)\n",
    "    # 随机生成输入\n",
    "    inputs = torch.randn(B, T, input_size)\n",
    "    hs, cs = torch.randn((2 * num_layers, B, hidden_size)).chunk(2, 0)\n",
    "    re = inputs\n",
    "    # 取出模型参数\n",
    "    for layer_index in range(num_layers):\n",
    "        l = ref_model.all_weights[layer_index]\n",
    "        if layer_index == 0:\n",
    "            model = LSTM(input_size, hidden_size)\n",
    "        else:\n",
    "            model = LSTM(hidden_size, hidden_size)\n",
    "        i, f, c, o = torch.cat((l[0], l[1]), dim=1).chunk(4, 0)\n",
    "        ib, fb, cb, ob = (l[2] + l[3]).chunk(4, 0)\n",
    "        # 设置模型参数\n",
    "        model.cell.in_gate.weight = nn.Parameter(i)\n",
    "        model.cell.in_gate.bias = nn.Parameter(ib)\n",
    "        model.cell.forget_gate.weight = nn.Parameter(f)\n",
    "        model.cell.forget_gate.bias = nn.Parameter(fb)\n",
    "        model.cell.new_cell_state.weight = nn.Parameter(c)\n",
    "        model.cell.new_cell_state.bias = nn.Parameter(cb)\n",
    "        model.cell.out_gate.weight = nn.Parameter(o)\n",
    "        model.cell.out_gate.bias = nn.Parameter(ob)\n",
    "        # 计算隐藏状态\n",
    "        re = model(re, (hs[layer_index], cs[layer_index]))\n",
    "    ref_re, _ = ref_model(inputs, (hs, cs))\n",
    "    # 验证计算结果（最后一层的隐藏状态是否一致）\n",
    "    out = torch.all(torch.abs(re - ref_re) < 1e-4)\n",
    "    return out, (B, T, input_size, hidden_size, num_layers)\n",
    "\n",
    "test_lstm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d621aad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharLSTM(nn.Module):\n",
    "    def __init__(self, vs):\n",
    "        super().__init__()\n",
    "        self.emb_size = 256\n",
    "        self.hidden_size = 128\n",
    "        self.embedding = nn.Embedding(vs, self.emb_size)\n",
    "        self.dp = nn.Dropout(0.4)\n",
    "        self.lstm1 = LSTM(self.emb_size, self.hidden_size)\n",
    "        self.ln1 = nn.LayerNorm(self.hidden_size)\n",
    "        self.lstm2 = LSTM(self.hidden_size, self.hidden_size)\n",
    "        self.ln2 = nn.LayerNorm(self.hidden_size)\n",
    "        self.lstm3 = LSTM(self.hidden_size, self.hidden_size)\n",
    "        self.ln3 = nn.LayerNorm(self.hidden_size)\n",
    "        self.lm = nn.Linear(self.hidden_size, vs)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: (B, T)\n",
    "        emb = self.embedding(x) # (B, T, C)\n",
    "        h = self.ln1(self.dp(self.lstm1(emb))) # (B, T, H)\n",
    "        h = self.ln2(self.dp(self.lstm2(h)))\n",
    "        h = self.ln3(self.dp(self.lstm3(h)))\n",
    "        out = self.lm(h) # (B, T, vs)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0e676f31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CharLSTM(\n",
       "  (embedding): Embedding(98, 256)\n",
       "  (dp): Dropout(p=0.4, inplace=False)\n",
       "  (lstm1): LSTM(\n",
       "    (cell): LSTMCell(\n",
       "      (forget_gate): Linear(in_features=384, out_features=128, bias=True)\n",
       "      (in_gate): Linear(in_features=384, out_features=128, bias=True)\n",
       "      (new_cell_state): Linear(in_features=384, out_features=128, bias=True)\n",
       "      (out_gate): Linear(in_features=384, out_features=128, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  (lstm2): LSTM(\n",
       "    (cell): LSTMCell(\n",
       "      (forget_gate): Linear(in_features=256, out_features=128, bias=True)\n",
       "      (in_gate): Linear(in_features=256, out_features=128, bias=True)\n",
       "      (new_cell_state): Linear(in_features=256, out_features=128, bias=True)\n",
       "      (out_gate): Linear(in_features=256, out_features=128, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  (lstm3): LSTM(\n",
       "    (cell): LSTMCell(\n",
       "      (forget_gate): Linear(in_features=256, out_features=128, bias=True)\n",
       "      (in_gate): Linear(in_features=256, out_features=128, bias=True)\n",
       "      (new_cell_state): Linear(in_features=256, out_features=128, bias=True)\n",
       "      (out_gate): Linear(in_features=256, out_features=128, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (ln3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  (lm): Linear(in_features=128, out_features=98, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_model = CharLSTM(len(tokenizer.ind2char)).to(device)\n",
    "l_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a2190dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def*$K(h]Rf(\"YS{BZE G|uw=3:1'_$=z9NN[{KQ=CK|AM:iKca\"|+Q3j<sA!!WS$I8tx!q*T3\"?u?5Za)'W*5\\rm&B\"T{Y\n",
      "cdtM\\SDAx1zk<|e|>\n"
     ]
    }
   ],
   "source": [
    "context = torch.tensor(tokenizer.encode('def'), device=device).unsqueeze(0)\n",
    "print(''.join(tokenizer.decode(generate(l_model, context, tokenizer))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d00721c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 4.749468803405762, 'test': 4.756665229797363}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimate_loss(l_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3f5881d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 | Train Loss: 1.2832 | Test Loss: 1.4375\n",
      "Epoch 2/10 | Train Loss: 1.1272 | Test Loss: 1.3084\n",
      "Epoch 3/10 | Train Loss: 1.0798 | Test Loss: 1.2798\n",
      "Epoch 4/10 | Train Loss: 1.0035 | Test Loss: 1.2374\n",
      "Epoch 5/10 | Train Loss: 0.9708 | Test Loss: 1.2185\n",
      "Epoch 6/10 | Train Loss: 0.9526 | Test Loss: 1.2099\n",
      "Epoch 7/10 | Train Loss: 0.9429 | Test Loss: 1.1949\n",
      "Epoch 8/10 | Train Loss: 0.9169 | Test Loss: 1.1891\n",
      "Epoch 9/10 | Train Loss: 0.9071 | Test Loss: 1.1910\n",
      "Epoch 10/10 | Train Loss: 0.9028 | Test Loss: 1.2064\n"
     ]
    }
   ],
   "source": [
    "l = train(l_model, optim.Adam(l_model.parameters(), lr=learning_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d09759d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
